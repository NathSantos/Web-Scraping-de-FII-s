# -*- coding: utf-8 -*-
"""webScraping.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1vy0m2PkhTCi2p2U9MaQhvILUx7VKGLbd

---
# <font color=orange> Web Scraping de FIIs
---

## <font color=orange> Obtendo conteúdo HTML de um site

**Importando as bibliotecas**
"""

import bs4
import urllib.request as urllib_request
import pandas as pd

print("BeautifulSoup ->", bs4.__version__)
print("urllib ->", urllib_request.__version__)
print("pandas ->", pd.__version__)

"""**Passando a requisição do site para o urllib**"""

from urllib import request
from urllib.request import Request, urlopen    
from bs4 import BeautifulSoup          

url = 'https://statusinvest.com.br/fundos-imobiliarios/trxf11'
request_site = Request(url, headers={"User-Agent": "Mozilla/5.0"})

response = urlopen(request_site)
html = response.read()

"""**Abrindo no BeautifulSoup**"""

soup = BeautifulSoup(html, 'html.parser')
print(soup.find('h1').get_text())

"""## <font color=orange> Tratamento de String

**Convertendo o tipo bytes para string**
"""

type(html)

html = html.decode('utf-8')
type(html)

"""**Eliminando os caracteres de tabulação, quebra de linha, etc**"""

" ".join(html.split())

"""**Eliminando os espaços em branco entre as TAGS**"""

" ".join(html.split()).replace('> <', '><')

"""**Função de tratamento de strings**"""

def trata_html(input):
    return " ".join(input.split()).replace('> <', '><')

html = trata_html(html)
html

"""## <font color=orange> HTML de uma página

### Estrutura básica 

```html
<html>
    <head>
        <meta charset="utf-8" />
        <title>Alura Motors</title>
    </head>
    <body>
        <div id="container">
            <h1>Alura</h1>
            <h2 class="formato">Cursos de Tecnologia</h2>
            <p>Você vai estudar, praticar, discutir e aprender.</p>
            <a href="https://www.alura.com.br/">Clique aqui</a>
        </div>
    </body>
</html>
```

```<html>``` - determina o início do documento.

```<head>``` - cabeçalho. Contém informações e configurações do documento.

```<body>``` - é o corpo do documento, onde todo o conteúdo é colocado. Esta é a parte visível em um navegador.

### Tags mais comuns

```<div>``` - define uma divisão da página. Pode ser formatada de diversas maneiras.

```<h1>, <h2>, <h3>, <h4>, <h5>, <h6>``` - marcadores de títulos.

```<p>``` - marcador de parágrafo.

```<a>``` - hiperlink.

```<img>``` - exibição de imagens.

```<table>``` - definição de tabelas.

```<ul>, <li>``` - definição de listas.

## <font color=orange> Criando um objeto BeautifulSoup
"""

from bs4 import BeautifulSoup

soup = BeautifulSoup(html, 'html.parser')
print(soup.prettify())

type(soup)

"""### <font color=orange> Acessando Tags"""

soup.title

soup.div

"""### <font color=orange> Acessando o conteúdo das Tags"""

soup.title.get_text()

soup.getText()

"""### <font color=orange> Acessando atributos de uma Tag"""

soup.img

soup.img.attrs  # acessando atributos

soup.img.attrs.keys()

soup.img.attrs.values()

soup.img['alt']

soup.img.get('src')

"""## <font color=orange> Pesquisando com BeautifulSoup

### <font color=orange> Métodos find() e findAll()

- find(tag, attributes, recursive, text, **kwargs)

- findAll(tag, attributes, recursive, text, limit, **kwargs)

<font color=orange> Método find()
"""

soup.find('img')

soup.img

"""<font color=orange> Método findAll()"""

soup.findAll('img')

soup.findAll('img', limit=3)    # limitando o número de resultados da pesquisa

soup.findAll('img', limit=3)[1]    # segundo resultado dentre os 3 primeiros

soup.findAll(['h1','h2','h3','h4','h5','h6'])   # procura por todas as tags presentes na lista

soup.findAll('h3', {"class": "title m-0"})  # especificando mais ainda a busca com o parâmetro attributes

soup.findAll('img', alt="Perfil do Twitter")    # utilizando diretamente os atributos

for item in soup.findAll('img'):    # posso utilizar dentro de um laço for
    print(item.get('src'))

soup.findAll(text = True)   # obtendo todo o conteúdo de texto de uma página

"""### <font color=orange> Outros métodos de pesquisa

- findParent(tag, attributes, text, **kwargs)
- findParents(tag, attributes, text, limit, **kwargs)
- findNextSibling(tag, attributes, text, **kwargs)
- findNextSiblings(tag, attributes, text, limit, **kwargs)
- findPreviousSibling(tag, attributes, text, **kwargs)
- findPreviousSiblings(tag, attributes, text, limit, **kwargs)

- findNext(tag, attributes, text, **kwargs)
- findAllNext(tag, attributes, text, limit, **kwargs)
- findPrevious(tag, attributes, text, **kwargs)
- findAllPrevious(tag, attributes, text, limit, **kwargs)

```html
<html>                  ----------------------> Parent
    <body>                  ------------------> Parent
        <div id="container-a">  --------------> Parent
            <h1>Título A</h1>       ----------> Previous Sibling
            <h2>Subtítulo A</h2>        ------> **Choosen**
            <p>Texto de conteúdo A</p>      --> Next Sibling
        </div>
    </body>
</html>
```
"""

html_teste = """
    <html>
        <body>
            <div id="container-a">
                <h1>Título A</h1>
                <h2 class="ref-a">Sub título A</h2>
                <p>Texto de conteúdo A</p>
            </div>
            <div id="container-b">
                <h1>Título B</h1>
                <h2 class="ref-b">Sub título B</h2>
                <p>Texto de conteúdo B</p>
            </div>
        </body>
    </html>
"""

soup_teste = BeautifulSoup(html_teste, 'html.parser')
print(soup_teste.prettify())

"""<font color=orange> Parents"""

soup_teste.find('h2').findParent()

soup_teste.find('h2').findParent('html')

soup_teste.find('h2').findParent('html')

soup_teste.find('h2').findParents()

"""<font color=orange> Siblings"""

soup_teste.find('h2').findNextSibling()

soup_teste.find('p').findPreviousSiblings()

"""<font color=orange> Next e Previous"""

soup_teste.find('h2').findNext()

soup_teste.find('h2').findPrevious()

"""## <font color=orange> Capturando dados de seções específicas

**Nesta parte estaremos capturando dados das seções de 'NEGOCIAÇÕES DO TRXF11', 'ÚLTIMO RENDIMENTO' e 'PRÓXIMO RENDIMENTO'**

### <font color=orange> Identificando e selecionando os dados no HTML

#### <font color="orange"> Obtendo o HTML e criando o objeto BeautifulSoup
"""

url = 'https://statusinvest.com.br/fundos-imobiliarios/trxf11'
request_site = Request(url, headers={"User-Agent": "Mozilla/5.0"})
response = urlopen(request_site)
html = response.read().decode('utf-8')
soup = BeautifulSoup(html, 'html.parser')
soup

"""#### <font color="orange"> Criando variáveis para armazenar informações"""

cards = []  # lista de cards
card = {}   # armazena informações de seções específicas do site (card)

"""#### <font color="orange"> Obtendo os dados do primeiro CARD"""

ultimo_rendimento = soup.find('div', {'id': 'dy-info'})
ultimo_rendimento

"""### <font color='orange'> Obtendo o valor do último rendimento (R$)"""

ultimo_rendimento.find('strong', {'class': 'value'}).getText()

card['último_rendimento'] = ultimo_rendimento.find('strong', {'class': 'value'}).getText()
card

"""### <font color='orange'> Obtendo outras informações sobre o último rendimento

#### <font color='orange'> Coletando as outras infos
"""

ultimo_rendimento.findAll('b')

infos = ultimo_rendimento.findAll('b')

for i in infos:
    print(i.getText())

"""#### <font color='orange'> Coletando os identificadores (nomes) dessas infos"""

ultimo_rendimento.findAll('small')

identifiers = ultimo_rendimento.findAll('small')

for i in identifiers:
    print(i.getText())

"""#### <font color='orange'> Adicionando no dicionário as infos (valores) com os identificadores (chaves)"""

cont = 0
for i in infos:
    card[identifiers[cont].getText()] = i.getText()
    cont+=1

card

"""### <font color='orange'> Criando um DataFrame com Pandas"""



